# Related 
Insieme di materiali utili per la tesi
## Dataset di Dockerfile 
2 dataset di dockerfiles: 
- https://cs.paperswithcode.com/paper/a-dataset-of-dockerfiles
- https://www.kaggle.com/datasets/stanfordcompute/dockerfiles/data

da questi valuteremo se possiamo migliorare le performance utilizzando un approccio di "fine-tuning" 

## Prompt engineering e fine-tuning LLM 

Ci sono due approcci per migliorare ChatGPT (se dobbiamo migliorarlo e non funziona già bene così) :  fare prompt engineering o fine tuning.

* Un introduzione al "prompt engineering" https://link.springer.com/article/10.1007/s10439-023-03272-4

* top 10 llm open-source https://deci.ai/blog/list-of-large-language-models-in-open-source/
