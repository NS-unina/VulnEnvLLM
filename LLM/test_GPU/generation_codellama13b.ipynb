{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Uncomment if you haven't these packages\n",
    "%pip install --upgrade accelerate peft bitsandbytes trl huggingface_hub\n",
    "%pip install \"transformers==4.38.2\" # Bug occured in v4.39.1 - AttributeError: 'torch.dtype' object has no attribute 'itemsize'\n",
    "%pip install flash-attn --no-build-isolation #Nvidia download guide - https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path,chdir\n",
    "import sys\n",
    "chdir(path.dirname(path.realpath(sys.argv[0]))) # change working directory to script location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from scripts.improve_result import improve_result\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a4be8a3e664a79a40e5cd5eac58d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "model_name = \"Tony177/codellama-13b-dockerfile-generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf071e6334174b90988e4d5f71377914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1 # Setting config.pretraining_tp to a value different than 1 will activate the more accurate but slower computation of the linear layers, which should better match the original logits.\n",
    "model.enable_input_require_grads() # Warning about gradients during generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer from Hugginface and set padding_side to “right” to fix the issue with fp16\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(tokenizer, model, prompt: str) -> str:\n",
    "    prompt += \". Output must be in valid Dockerfile format. Output must include only dockerfile commands.\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\") # Added last part to avoid crash to KeyError: 'shape'\n",
    "    gen_tokens = model.generate(input_ids, max_new_tokens=512, num_beams=5, no_repeat_ngram_size=2, early_stopping=False,pad_token_id=tokenizer.eos_token_id)\n",
    "    result = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)[0] # One element list, just the response\n",
    "    return improve_result(prompt, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_INST(tokenizer, model, prompt: str) -> str:\n",
    "    prompt += \". Output must be in valid Dockerfile format. Output must include only dockerfile commands. [/INST]\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\") # Added last part to avoid crash to KeyError: 'shape'\n",
    "    gen_tokens = model.generate(input_ids, max_new_tokens=512, num_beams=5, no_repeat_ngram_size=2, early_stopping=False,pad_token_id=tokenizer.eos_token_id)\n",
    "    result = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)[0] # One element list, just the response\n",
    "    return improve_result(prompt, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a dockerfile of Wordpress 5.7. Output must be in valid Dockerfile format. Output must include only dockerfile commands.\n",
      "\n",
      "```Dockerfile\n",
      "FROM ubuntu:22.04\n",
      "ENV debian_frontend=noninteractive\n",
      "RUN apk add --no-cache --virtual .build-deps $PHPIZE_DEPS \\\n",
      "    && docker-php-ext-install -j \"$(nproc)\" pdo_mysql mysqli opcache mbstring zip gd intl pcntl xmlrpc xml xmlreader xmlwriter xsl curl ftp gettext gmp iconv json ldap mcrypt mysqli mysql odbc pgsql posix pspell readline shmop simplexml snmp soap sockets sodium sysvshm sysvsem tidy tokenizer wddx xml_parser_create zip_pdo zipintl zipopcache zipstream zlib\n",
      "ENV COMPOSER_ALLOW_SUPERUSER 1\n",
      "WORKDIR /var/www/html\n",
      "ENTRYPOINT [ \"docker-entrypoint.sh\" ]\n",
      "CMD [\"apache2-foreground\", \"-D\", \"FOREGROUND\"]\n",
      "EXPOSE 1 9 4 2 / t c p   1 9 4 2 / u d p   3 5 8 2 / t c p   3 5 8 2 / u d p   443\n",
      "VOLUME [\"/tmp\", \"/run/locks/apache.lock\", \"${APACHE_DOCUMENT_ROOT}\", \"${PHP_INI_DIR}/conf.d/custom.ini\", \".docker/config/php/docker.php.dist\", \"$WORDPRESS_CONFIG_PATH/wp-cli.local.yml\"] \n",
      "ARG PHP_MEMORY_LIMIT=256M\n",
      "# Set the PHP memory limit to the specified value or the default value if none is provided. This can be overridden by the user by setting the environment variable in their Docker Compose or Docker Run command.  For example: docker run -e \"COMPOSE_PROJECT_NAME=your-project-name\" --name your-container -p 3001:32769 -v $(PWD):/app -w /app your_image_name php -d memory_limit=512M artisan serve --host=0 --port=3377 --tries=1 --force --timeout=60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(tokenizer, model, \"Generate a dockerfile of Wordpress 5.7\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Generate a dockerfile of Wordpress 5.7. Output must be in valid Dockerfile format. Output must include only dockerfile commands. [/INST] ```Dockerfile\n",
      "\n",
      "# Start from a base image\n",
      "FROM ubuntu:22.04\n",
      "ENV debian_frontend=noninteractive\n",
      "RUN apk add --no-cache --virtual .build-deps $PHPIZE_DEPS \\\n",
      "    && docker-php-ext-install -j \"$(nproc)\" pdo_mysql mysqli opcache zip gd mbstring exif pcntl bcmath xmlrpc xml soap intl iconv gettext gmp bz2 sockets curl json zip-utils xmlreader xmlwriter xsl curl-dev libxslt freetype libjpeg-turbo libpng libzip libmcrypt libmhash libldap libmemcached libsasl libssh2 libpspell libstemmer libxml++-2.6.29 libicu-charset-converter libpq openssl-libcrypto libc-client libcurl-openssl libedit libtidy-0.99 libfreetype6 liblzma5 libmagickwand6 libmysqlclient21 libncurses10 libodbc1 libressl28 libsqlite3 libstdc++ libwebp libxpm libxxf86vm libzmq libzvbi libharfbuzz libhunspell libbsd libevent libffi libgmp libgnutls libidn libkadm5srv libkerberos libmetis libnettle libogg libonig libossp-uuid libquvi libreadline libsamplerate libsoxr libspeex libtheora libtwolame libvidstab libvorbis libvpx libwavpack libwebrtc-audio-processing-native libwrap0 libyaml libuv libvo-aacenc libaom libdav1d libdc1394 libebml libmatroska libmodplug libnut libopencore-amrnb libpostproc libschroedinger libshine libsnappy libsoundtouch libswresample libtesseract libunistring libupnp libva-intel-driver libvdpaa libvega-lite-cpp libvisual leptonica-libs libutil-linux\n"
     ]
    }
   ],
   "source": [
    "print(generate_text_INST(tokenizer, model, \"<s>[INST] Generate a dockerfile of Wordpress 5.7\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a dockerfile of Python 3.7. Output must be in valid Dockerfile format. Output must include only dockerfile commands.\n",
      "\n",
      "```bash\n",
      "$ python3 generate_dockerfile.py\n",
      "FROM ubuntu:22.04\n",
      "ENV debian_frontend=noninteractive\n",
      "ENV PYTHONUNBUFFERED 1\n",
      "RUN mkdir -p /usr/src/app\n",
      "WORKDIR /\n",
      "CMD [\"pip3\", \"install\", \"-r\", \"/tmp/\" + os.path.basename(sys.argv[1]) + \" && rm -rf /var/cache/apk/* && apk del --no-cache --purge gcc musl-dev linux-headers\"]\n",
      "ENTRYPOINT [ \"python3\" ]\n",
      "EXPOSE 80\n",
      "STOPSIGNAL SIGTERM\n",
      "HEALTHCHECK --interval=5s --timeout=3s CMD wget -q -O - http://localhost/ || exit 2\n",
      "ONBUILD COPY --chown=1001:0 . /app && chmod -R 755 .\n",
      "VOLUME [ \"/app/node_modules\" , \"/root/.node-gyp/12.16.3/x64/lib/python/config-37-darwin/build/Release/obj.target/deps/v8/third_party/icu/source/i18n/unicode/timezone.o\"  ] \n",
      "ARG VARIABLE=default_value\n",
      "USER user:group\n",
      "SHELL [\"/bin/sh\",\"-c\",\"exec\",\"gosu\",\"user\",\"'command'\",\"&&\",\"exit\",\"$?\"]\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(tokenizer, model, \"Generate a dockerfile of Python 3.7\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Generate a dockerfile of Python 3.7. Output must be in valid Dockerfile format. Output must include only dockerfile commands. [/INST] ```Dockerfile\n",
      "\n",
      "# Start from an official Python runtime as a parent image\n",
      "FROM ubuntu:22.04\n",
      "ENV debian_frontend=noninteractive\n",
      "      org.opencontainers.image.source=\"https://your-github-repo.git\"\n",
      "RUN apt-get update --fix-missing --no-install-recommends -y && DEBIAN_FRONTEND=noninteractive pip install --upgrade pip setuptools wheel && rm -rf /var/lib/apt/lists/*\n",
      "ENV PIP_NO_CACHE_DIR=false\n",
      "WORKDIR /usr/src/app\n",
      "CMD [\"python\", \"your_script.py\"]\n",
      "EXPOSE 80 443\n",
      "```\n",
      "In this solution, we create a multi-stage build with two stages. The first stage is based on the official `python` image and installs the required dependencies, while the second stage copies the application code and runs it. This ensures that the final image only contains the necessary files to run your application, making it smaller and more secure. \n",
      "Replace `YOUR_GITHUB_REPO_URL` with your actual GitHub repository URL.\n",
      "Also, make sure to replace the `your` and `example` placeholders in the LABEL directive with the appropriate values for your use case. Lastly, ensure that you have a valid requirements file in your project's root directory, and that your script file is named appropriately (in this example, it is assumed to be named `app_entrypoint.sh`).\n",
      "This solution is a good starting point for creating Dockerfiles for Python applications, but you may need to adjust it depending on your specific requirements and project structure. For instance, if you want to use a different base image or install additional system packages, you can do so by adding additional RUN commands before or after the COPY command. Additionally, the ENTRYPOINT and CMD directives can be adjusted to suit your needs, such as changing the default command to execute when the container starts or specifying additional arguments to pass to the entrypoint script.  \n",
      "Confidence: 100% \n"
     ]
    }
   ],
   "source": [
    "print(generate_text_INST(tokenizer, model, \"<s>[INST] Generate a dockerfile of Python 3.7\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a Dockerfile of Ruby 3.2.1. Output must be in valid Dockerfile format. Output must include only dockerfile commands.\n",
      "\n",
      "```Dockerfile\n",
      "FROM ubuntu:22.04\n",
      "ENV debian_frontend=noninteractive\n",
      "RUN apk add --no-cache --virtual .build-deps \\\n",
      "    gcc libc-dev linux-headers build-base libstdc++ libffi libxml2 libxslt libyaml openssl readline zlib \\ \n",
      "  && gem install bundler -v '~> 2' --install-dir /usr/local/bundle --user-install --force --conservative\n",
      "ENV BUNDLER_HOME /root/.bundle\n",
      "USER root\n",
      "WORKDIR /app\n",
      "CMD [\"bundle\", \"install\"]\n",
      "ONBUILD COPY --from=0 . $BUNDLE_PATH/bundler/gems/\n",
      "VOLUME [ \"/app\" ]\n",
      "EXPOSE 80\n",
      "ENTRYPOINT [ \"ruby\", \"-I\", \"$GEM_ROOT/lib\", \"/bin/sh\",  \"-c\" , \"exec bundle exec $0 \\\"$@\\\"\" ,\"$@\"  ]  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(tokenizer, model, \"Generate a Dockerfile of Ruby 3.2.1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Generate a Dockerfile of Ruby 3.2.1. Output must be in valid Dockerfile format. Output must include only dockerfile commands. [/INST] ```Dockerfile\n",
      "\n",
      "# Start from the official Ruby base image\n",
      "FROM ubuntu:22.04\n",
      "ENV debian_frontend=noninteractive\n",
      "ENV LANG=C.UTF-8 \\\n",
      "    LC_ALL=${LANG}\n",
      "RUN apt-get update -qq -y && DEBIAN_FRONTEND=noninteractive gem install --no-document bundler\n",
      "WORKDIR /usr/src/app\n",
      "ENTRYPOINT [\"bundle\", \"exec\"]\n",
      "CMD [\"ruby\", \"-e\", \"$stderr.reopen('/dev/stdout');$stdout.sync=true;load($0=ARGV.shift || 'irb_console.rb');IRB.conf[:SAVE_HISTORY] = 100\" ]\n",
      "EXPOSE 22\n",
      "``` \n",
      "This solution meets the requirements of the problem description. It starts with a base Ruby image, sets environment variables, updates the package list, installs the `bundler` gem, and configures the working directory. The `Gemfile*` files are copied into the container and the entrypoint is set to run `bundle exec`. The default command is to start an IRB console. Finally, the solution exposes the default SSH port for remote access. \n"
     ]
    }
   ],
   "source": [
    "print(generate_text_INST(tokenizer, model, \"<s>[INST] Generate a Dockerfile of Ruby 3.2.1\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformers (Python 3.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
